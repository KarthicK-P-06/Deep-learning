import tensorflow as tf
import tensorflow.keras.layers as tfl
import os

url = "https://data.vision.ee.ethz.ch/cvl/rrothe/imdbwiki/static/wiki_crop.tar"
dataset = tf.keras.utils.get_file(
  "wiki_crop", url,
  untar=True, cache_dir='.',
  cache_subdir=''
)
dataset_dir = os.path.join(os.path.dirname(dataset), 'wiki_crop')

import scipy.io

mat = scipy.io.loadmat(os.path.join(dataset_dir,'wiki.mat'))
import numpy as np
import datetime
mat

mat["wiki"]["dob"][0][0][0]

dob = np.vectorize(lambda x: datetime.datetime.fromordinal(x).year)(
  mat["wiki"]["dob"][0][0][0]
)
photo_taken = mat["wiki"]["photo_taken"][0][0][0]
age = (photo_taken-dob).astype(np.float32)
age

mat["wiki"]["full_path"][0][0][0]

file_path = np.vectorize(lambda x : os.path.join(dataset_dir,x[0]))(
  mat["wiki"]["full_path"][0][0][0]
)
file_path

file_age_ds = tf.data.Dataset.from_tensor_slices((file_path,age))
def parse_function(filename, label):
  image_string = tf.io.read_file(filename)
  image_decoded = tf.io.decode_jpeg(image_string,channels=1)
  image = tf.image.resize(image_decoded, [256, 256])
  return image, tf.expand_dims(label,0)
image_age_ds=file_age_ds.map(parse_function).shuffle(seed=2,buffer_size=64)
image_age_ds

dataset_size = image_age_ds.cardinality().numpy()
AUTOTUNE = tf.data.AUTOTUNE
train_ds = image_age_ds.take(dataset_size*.6).batch(32).prefetch(AUTOTUNE)
val_ds = image_age_ds.skip(dataset_size*.6).take(dataset_size*.2).batch(32).prefetch(AUTOTUNE)
test_ds = image_age_ds.skip(dataset_size*.8).take(dataset_size*.2).batch(32).prefetch(AUTOTUNE)

model = tf.keras.Sequential([
tfl.Conv2D(32,(7,7),padding="valid",activation="relu",input_shape=(256,256,1)),
tfl.MaxPool2D((4,4),strides = 4),
tfl.Conv2D(64,(3,3),padding = "valid",activation="relu"),
tfl.MaxPool2D((4,4),strides = 4),
tfl.Conv2D(128,(3,3),padding = "valid",activation="relu"),
tfl.MaxPool2D((2,2),strides = 2),
tfl.Conv2D(256,(1,1),padding= "valid",activation="relu",),
tfl.MaxPool2D((2,2),strides = 2),
tfl.Flatten(),
tfl.Dense(64,activation="relu"),
tfl.Dense(1)
])
model.summary()

model.compile(
  optimizer='adam',
  loss=tf.keras.losses.MeanAbsoluteError(),
  metrics=['MAE']
)
model.fit(
  train_ds,
  validation_data=val_ds,
  epochs=10,
  callbacks=[
    tf.keras.callbacks.TensorBoard(log_dir="logs")
  ]
)

loss, accuracy = model.evaluate(test_ds)
print("Loss: ", loss)
print("Accuracy: ", accuracy)
